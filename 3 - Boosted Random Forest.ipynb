{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ames Housing Dataset - Adaboost with Random Forest estimator\n",
    "\n",
    "> Gianmaria Pizzo - 872966@stud.unive.it\n",
    "\n",
    "These notebooks represent the project submission for the course [Data and Web Mining](https://www.unive.it/data/course/337525) by Professor [Claudio Lucchese](https://www.unive.it/data/people/5590426) at [Ca' Foscari University of Venice](https://www.unive.it).\n",
    "\n",
    "---\n",
    "\n",
    "## Structure of this notebook\n",
    "\n",
    "This notebook covers the following points\n",
    "* The idea\n",
    "* GridSearchCV Hyperparameters tuning for R.F.\n",
    "* Model validation\n",
    "    * For different counts of estimators\n",
    "    * For different learning rate\n",
    "* Results\n",
    "\n",
    "---\n",
    "\n",
    "### Before running this notebook\n",
    "\n",
    "To avoid issues, before running the following notebook it is best to\n",
    "* Clean previous cell outputs\n",
    "* Restart the kernel\n",
    "\n",
    "---\n",
    "\n",
    "## The idea - Combining AdaBoost and Random Forest\n",
    "\n",
    "As we know, different predictors have different flaws and strengths. This means we can train multiple models in order to exploit what they learnt and obtain a more accurate result.\n",
    "\n",
    "[Khulna University of Engineering and Technology](https://www.researchgate.net/institution/Khulna_University_of_Engineering_and_Technology) published a research article about the use of Random Forest as base estimators for AdaBoost in order to create a model for breast cancer detection, which can be found [here](https://www.researchgate.net/publication/339978251_A_Precise_Breast_Cancer_Detection_Approach_Using_Ensemble_of_Random_Forest_with_AdaBoost). \n",
    "Although used as a binary classifier, the results were impressive: \"*The structure provided accuracy of 98.5714% along with sensitivity and specificity of 100% and 96.296% respectively in the testing phase*\" states the abstract.\n",
    "\n",
    "It seemed a good idea to use an ensemble of ensembles, in order to get a more accurate result.\n",
    "\n",
    "As we are using random forests, we expect to find some level of overfitting when testing it on the dataset where the outliers and most noise were removed. Plus, as the dataset shows very few instances, it migth be better to use this kind of model on a larger dataset.\n",
    "However, there should be some level of improvement given the boosting algorithm will try to lower the bias and the random forest can handle well the categorical variables which are present here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import IPython\n",
    "\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"darkgrid\")\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Working folder\n",
    "WORKING_DIR = os.getcwd()\n",
    "# Resources folder\n",
    "RESOURCES_DIR = os.path.join(os.getcwd(), 'resources')\n",
    "\n",
    "# Original\n",
    "IN_LABEL_ORIG = 'ames_housing_out_2_orig.csv'\n",
    "# Modified\n",
    "IN_LABEL_MOD = 'ames_housing_out_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(RESOURCES_DIR, IN_LABEL_MOD))\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "df_or = pd.read_csv(os.path.join(RESOURCES_DIR, IN_LABEL_ORIG))\n",
    "df_or.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_alphabetically(dataset, last_label = None):\n",
    "    \"\"\"\n",
    "    Sorts the dataset alphabetically \n",
    "\n",
    "    :param dataset: a pd.DataFrame\n",
    "    :param last_label: a str containing an existing column label in the dataset\n",
    "    :returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Sort\n",
    "    dataset = dataset.reindex(sorted(dataset.columns), axis=1)\n",
    "    # Move target column to last index\n",
    "    if last_label is not None:\n",
    "        col = dataset.pop(last_label)\n",
    "        dataset.insert(dataset.shape[1], last_label, col)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=sort_alphabetically(df, 'Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(dataset, label, ignore=None):\n",
    "    \"\"\"\n",
    "    Returns X and y and ignores labels in ignore\n",
    "    :param dataset: a pd.DataFrame\n",
    "    :param label: a str containing an existing target column label in the dataset\n",
    "    :param ignore: a str containing an existing column label in the dataset to ignore\n",
    "    :returns: tuple of pd.DataFrame X, y\n",
    "    \"\"\"\n",
    "    if ignore is not None:\n",
    "        # Drop the labels\n",
    "        return dataset.drop(columns=[label, ignore]), dataset.loc[:,[label]]\n",
    "    return dataset.drop(columns=[label]), dataset.loc[:,[label]]\n",
    "\n",
    "def get_train_test(X, y, size = 0.2, state = 33):\n",
    "    \"\"\"\n",
    "    Returns X_train_[size], X_test, y_train_[size], y_test\n",
    "    :param X: a pd.DataFrame without the target column\n",
    "    :param y: a pd.DataFrame with one column, the target\n",
    "    :param size: a float representing the fraction for the test size\n",
    "    :param state: an integer representing the random state for the test\n",
    "    :returns: 4 pd.DataFrame usually called \"X_train_[size], X_test, y_train_[size], y_test\"\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=size, random_state = state)\n",
    "\n",
    "def get_train_val_test(X, y, size_t=0.2, size_v=0.25, state_v = 42):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    :param X: a pd.DataFrame without the target column\n",
    "    :param y: a pd.DataFrame with one column, the target\n",
    "    :param size_t: a float representing the fraction for the test size\n",
    "    :param size_v: a float representing the fraction for the validation\n",
    "    :param state_v: an integer representing the random state for the validation\n",
    "    :returns: 6 pd.DataFrame usually called X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    \"\"\"\n",
    "    X_train_s, X_test, y_train_s, y_test = get_train_test(X, y, size = size_t)\n",
    "    X_train, X_valid, y_train, y_valid = get_train_test(X_train_s, y_train_s, size = size_v, state = state_v)\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "As we know from https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769\n",
    "\n",
    "Because this procedure generates several new variables, it is prone to causing a large problem (too many predictors) if the original column has a large number of unique values. Another disadvantage of one-hot encoding is that it produces multicollinearity among the various variables, lowering the model's accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hyperparameters Tuning for R.F. estimator\n",
    "\n",
    "Since the R.F. is largely customizable when it comes to its parameters, the GridSearchCV seems the way to go. This allows for the use of Cross Validation.\n",
    "\n",
    "We are going to this **two times considering the two different targets** `Sale_Price` and `Log1p_Sale_Price`. We are not going to exclude the outliers as the R.F. \n",
    "\n",
    "The best parameters are selected and a score is returned for the resulting model. It is possible to feed these parameters to the estimator before the latter is used by the AdaBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error, r2_score, max_error \n",
    "\n",
    "scoring = {\n",
    "    \"MSE\":\"neg_mean_squared_error\",\n",
    "    \"MSLE\":\"neg_mean_squared_log_error\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAXERROR\": \"max_error\"\n",
    "}\n",
    "    \n",
    "random_grid = {\n",
    "    'criterion':('squared_error', 'absolute_error', 'friedman_mse', 'poisson'),\n",
    "    'max_depth':[8, 10, 12],\n",
    "    'min_samples_split': [5,10, 8, 12, 15],\n",
    "    'min_samples_leaf': [10, 12, 15, 17, 20],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_leaf_nodes': [10, 15, 20, 25],\n",
    "    'random_state':[2324, 159857, 21412],\n",
    "    'max_samples':[800, 900, 1000, 1050, 1100]\n",
    "}\n",
    "\n",
    "# Base estimator\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Grid Search CV with 10 fold \n",
    "tuned_model = RandomizedSearchCV(\n",
    "    estimator = rf, param_distributions = random_grid, refit='MSE',\n",
    "    scoring = scoring, n_iter=50,\n",
    "    cv=5, verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_or['Log1p_Sale_Price'] = np.log1p(df_or['Sale_Price'])\n",
    "X_or, y_or = get_X_y(df_or.select_dtypes(exclude=['object']), label = 'Sale_Price', ignore = 'Log1p_Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1212147335.083\n",
      "Best Params:  {'random_state': 159857, 'min_samples_split': 10, 'min_samples_leaf': 12, 'max_samples': 1050, 'max_leaf_nodes': 25, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'poisson'}\n"
     ]
    }
   ],
   "source": [
    "# 1 - Original Data, Sale_Price\n",
    "\n",
    "tuned_model.fit(X_or, y_or)\n",
    "\n",
    "print (\"Best Score: {:.3f}\".format(tuned_model.best_score_) )\n",
    "print (\"Best Params: \", tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_or_log, y_or_log = get_X_y(df_or.select_dtypes(exclude=['object']), label = 'Log1p_Sale_Price', ignore = 'Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.033\n",
      "Best Params:  {'random_state': 2324, 'min_samples_split': 12, 'min_samples_leaf': 12, 'max_samples': 1050, 'max_leaf_nodes': 25, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "# 2 - Original Data, Log1p Sale_Price\n",
    "\n",
    "tuned_model.fit(X_or_log, y_or_log)\n",
    "\n",
    "print (\"Best Score: {:.3f}\".format(tuned_model.best_score_) )\n",
    "print (\"Best Params: \", tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mod, y_mod = get_X_y(df.select_dtypes(exclude=['object']), label = 'Sale_Price', ignore = 'Log1p_Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -887434029.521\n",
      "Best Params:  {'random_state': 159857, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_samples': 1050, 'max_leaf_nodes': 25, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'poisson'}\n"
     ]
    }
   ],
   "source": [
    "# 3 - Engineered Data, Sale_Price\n",
    "\n",
    "tuned_model.fit(X_mod, y_mod)\n",
    "\n",
    "print (\"Best Score: {:.3f}\".format(tuned_model.best_score_) )\n",
    "print (\"Best Params: \", tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mod_log, y_mod_log = get_X_y(df.select_dtypes(exclude=['object']), label ='Log1p_Sale_Price', ignore = 'Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.022\n",
      "Best Params:  {'random_state': 159857, 'min_samples_split': 12, 'min_samples_leaf': 12, 'max_samples': 900, 'max_leaf_nodes': 25, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "# 4 - Engineered Data, Log1p Sale_Price\n",
    "\n",
    "tuned_model.fit(X_mod_log, y_mod_log)\n",
    "\n",
    "print (\"Best Score: {:.3f}\".format(tuned_model.best_score_) )\n",
    "print (\"Best Params: \", tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final hyperparameters\n",
    "\n",
    "# Sale_Price\n",
    "rf_sp_param = {'random_state': 159857, \n",
    "               'min_samples_split': 10, \n",
    "               'min_samples_leaf': 12, \n",
    "               'max_samples': 800, \n",
    "               'max_leaf_nodes': 25, \n",
    "               'max_features': 'sqrt', \n",
    "               'max_depth': 10, \n",
    "               'criterion': 'poisson'}\n",
    "\n",
    "# Log1p Sale Price\n",
    "\n",
    "rf_logsp_param = {'random_state': 159857, \n",
    "               'min_samples_split': 10, \n",
    "               'min_samples_leaf': 12, \n",
    "               'max_samples': 800, \n",
    "               'max_leaf_nodes': 25, \n",
    "               'max_features': 'sqrt', \n",
    "               'max_depth': 10, \n",
    "               'criterion': 'poisson'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some good hyperparameters, we shall see how the accuracy changes with regards to the number of estimators. In fact, we need to limit this value as we are combining two ensemble methods and this could lead to overfitting and high time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 40, 50, 80, 100, 120, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AdaBoost with R.F.\n",
    "\n",
    "Now that we have some good hyperparameters for the estimator, we can closely analyze how accurate the model is.\n",
    "\n",
    "To cut short through the choice of the number of estimators (considering they are ensemble too), we leave the decision to the GridSearchCV, once a again. This is because we want to focus on another aspect: the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for n_estimators and loss\n",
    "\n",
    "adab_parameters = {\n",
    "    'n_estimators':[5, 10, 25, 50, 100],\n",
    "    'learning_rate':[0.01,0.1, 1.0, 2.0, 5.0, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle to see how the learning rate affects prediction on log1p Sale_Price and Sale_Price\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    # lst_accu_stratified = []  \n",
    "    # for train_index, test_index in skf.split(x, y):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train-Val-Test 1: Regression on `Sale_Price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Split 60/20/20\n",
    "# 80% Train, 20% Test\n",
    "X_train_80, X_test, y_train_80, y_test = train_test_split(df_train, df_target,\n",
    "                                                          test_size = 0.20, random_state = 33)\n",
    "# %80 Train -> 55% Train, 25% Validate\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(X_train_80, y_train_80, \n",
    "                                                       test_size=0.25, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
    "    # train and predict\n",
    "    model = SVC(C=c, kernel='poly')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # compute Accuracy\n",
    "    train_acc = accuracy_score(y_true = y_train, \n",
    "                               y_pred = model.predict(X_train))\n",
    "    valid_acc = accuracy_score(y_true = y_valid, \n",
    "                               y_pred = model.predict(X_valid))\n",
    "    print (\"C: {:8.3f} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f}\"\n",
    "           .format( c, train_acc, valid_acc) )\n",
    "    \n",
    "    accuracies += [ [valid_acc, c] ]\n",
    "\n",
    "best_accuracy, best_c = max(accuracies)\n",
    "print ( \"Best C:\", best_c )\n",
    "\n",
    "# here we are using both training and validation,\n",
    "# to exploit the most data\n",
    "model = SVC(C=best_c, kernel='poly')\n",
    "model.fit(X_train_80,y_train_80)\n",
    "\n",
    "test_acc = accuracy_score(y_true = y_test, \n",
    "                          y_pred = model.predict(X_test) )\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train_80, X_test, y_train_80, y_test = train_test_split(df_train, df_target,\n",
    "                                                          test_size = 0.20, random_state = 42)\n",
    "\n",
    "model = SVC()\n",
    "parameters = { 'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "        \n",
    "tuned_model = GridSearchCV(model, parameters, cv=5, verbose=0)\n",
    "tuned_model.fit(X_train_80, y_train_80)\n",
    "\n",
    "print (\"Best Score: {:.3f}\".format(tuned_model.best_score_) )\n",
    "print (\"Best Params: \", tuned_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( tuned_model.cv_results_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = accuracy_score(y_true = y_test, \n",
    "                          y_pred = tuned_model.predict(X_test) )\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train-Val-Test 2: Regression on `Log1p_Sale_Price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}