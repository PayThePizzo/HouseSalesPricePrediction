{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ames Housing Dataset -  Graph Neural Network\n",
    "\n",
    "> Gianmaria Pizzo - 872966@stud.unive.it\n",
    "\n",
    "These notebooks represent the project submission for the course [Data and Web Mining](https://www.unive.it/data/course/337525) by Professor [Claudio Lucchese](https://www.unive.it/data/people/5590426) at [Ca' Foscari University of Venice](https://www.unive.it).\n",
    "\n",
    "---\n",
    "\n",
    "## Structure of this notebook\n",
    "\n",
    "This notebook covers the following points\n",
    "* Graph Representation\n",
    "* Graph encoding of the dataset\n",
    "* GNN definition\n",
    "* GNN training and hyperparameter tuning\n",
    "* GNN test and evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Before running this notebook\n",
    "\n",
    "To avoid issues, before running the following notebook it is best to\n",
    "* Clean previous cell outputs\n",
    "* Restart the kernel\n",
    "* Be sure of having CUDA installed or use the CPU version\n",
    "\n",
    "---\n",
    "\n",
    "## Why Graphs?\n",
    "\n",
    "For many problems, switching to graph representation, helps us change the point of view on our problem\n",
    "\n",
    "By creating as many edges as the surrounding neighbors for each house, we can exploit the message passing layers to use the concept of proximity and the give features.\n",
    "\n",
    "This process aims to mimic the real estate evaluation of price where the surrounding houses play a big role on the final result.\n",
    "\n",
    "In fact, \"*we will show that GNNs and graph filters are equivariant to permutations so, they are able to exploit signal symmetries. This fundamental property allows both graph filters and GNN to outperform linear regression and FCNN*\" states the professor of the course [Graph Neural Networks from Penn Engineering](https://gnn.seas.upenn.edu/lectures/lecture-8/#:~:text=In%20this%20lecture%2C%20we%20come,outperform%20linear%20regression%20and%20FCNN.)\n",
    "\n",
    "### Environment, Imports and Global Variables\n",
    "\n",
    "This step requires the following libraries and eventually a GPU for better computing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: requests in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cpu.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cpu.html\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (0.6.17)\n",
      "Requirement already satisfied: scipy in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-sparse) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from scipy->torch-sparse) (1.20.3)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cpu.html\n",
      "Requirement already satisfied: torch-cluster in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-cluster) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from scipy->torch-cluster) (1.20.3)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cpu.html\n",
      "Requirement already satisfied: torch-spline-conv in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (1.20.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (1.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (1.10.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from scikit-learn->torch-geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\paythepizzo\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def format_pytorch_version(version):\n",
    "    if version is not None: \n",
    "        return version.split('+')[0]\n",
    "    return 'Not Available'\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    if version is not None:\n",
    "        return 'cu' + version.replace('.', '')\n",
    "    return 'cpu'\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-geometric \n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive\n",
    "%matplotlib notebook\n",
    "# Static\n",
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import warnings\n",
    "import IPython\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"darkgrid\")\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Working folder\n",
    "WORKING_DIR = os.getcwd()\n",
    "# Resources folder\n",
    "RESOURCES_DIR = os.path.join(os.getcwd(), 'resources')\n",
    "# Name of file\n",
    "IN_LABEL = 'ames_housing_out_2.csv'\n",
    "ORIG_LABEL = 'ames_housing_out_2_orig.csv'\n",
    "\n",
    "def sort_alphabetically(dataset, last_label = None):\n",
    "    \"\"\"\n",
    "    Sorts the dataset alphabetically \n",
    "\n",
    "    :param dataset: a pd.DataFrame\n",
    "    :param last_label: a str containing an existing column label in the dataset\n",
    "    :returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Sort\n",
    "    dataset = dataset.reindex(sorted(dataset.columns), axis=1)\n",
    "    # Move target column to last index\n",
    "    if last_label is not None:\n",
    "        col = dataset.pop(last_label)\n",
    "        dataset.insert(dataset.shape[1], last_label, col)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets we are going to consider are mainly 4:\n",
    "* The original dataset, fully encoded to float \n",
    "* The modified dataset, fully encoded to float\n",
    "* The original dataset, where we use the logarithm transformations instead of the original variables\n",
    "* The modified dataset, where we use the logarithm transformations instead of the original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(RESOURCES_DIR, IN_LABEL))\n",
    "df_orig = pd.read_csv(os.path.join(RESOURCES_DIR, ORIG_LABEL))\n",
    "\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_orig.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sort_alphabetically(df, 'Sale_Price')\n",
    "df_orig = sort_alphabetically(df_orig, 'Sale_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2638 entries, 0 to 2637\n",
      "Data columns (total 52 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Age                      2638 non-null   float64\n",
      " 1   Attchd                   2638 non-null   float64\n",
      " 2   Bedroom_AbvGr            2638 non-null   float64\n",
      " 3   Bedroom_Liv_Area_Ratio   2638 non-null   float64\n",
      " 4   Bsmt                     2638 non-null   float64\n",
      " 5   Bsmt_Cond                2638 non-null   float64\n",
      " 6   Bsmt_Exposure            2638 non-null   float64\n",
      " 7   Bsmt_Full_Bath           2638 non-null   float64\n",
      " 8   Bsmt_Half_Bath           2638 non-null   float64\n",
      " 9   Bsmt_Qual                2638 non-null   float64\n",
      " 10  Central_Air              2638 non-null   float64\n",
      " 11  Exter_Cond               2638 non-null   float64\n",
      " 12  Exter_Qual               2638 non-null   float64\n",
      " 13  External_SF              2638 non-null   float64\n",
      " 14  Fireplace_Gr_Area_Ratio  2638 non-null   float64\n",
      " 15  Fireplace_Qu             2638 non-null   float64\n",
      " 16  Fireplaces               2638 non-null   float64\n",
      " 17  First_Flr_SF             2638 non-null   float64\n",
      " 18  Full_Bath                2638 non-null   float64\n",
      " 19  Garage_Area              2638 non-null   float64\n",
      " 20  Garage_Cars              2638 non-null   float64\n",
      " 21  Garage_Cond              2638 non-null   float64\n",
      " 22  Garage_Qual              2638 non-null   float64\n",
      " 23  Gr_Area_Rms_Ratio        2638 non-null   float64\n",
      " 24  Gr_Liv_Area              2638 non-null   float64\n",
      " 25  Kitchen_AbvGr            2638 non-null   float64\n",
      " 26  Kitchen_Qual             2638 non-null   float64\n",
      " 27  Latitude                 2638 non-null   float64\n",
      " 28  Longitude                2638 non-null   float64\n",
      " 29  Lot_Area                 2638 non-null   float64\n",
      " 30  LowQ_Total_Liv_Ratio     2638 non-null   float64\n",
      " 31  Low_Qual_Fin_SF          2638 non-null   float64\n",
      " 32  Mas_Vnr_Area             2638 non-null   float64\n",
      " 33  Mo_Sold                  2638 non-null   float64\n",
      " 34  No_Garage                2638 non-null   float64\n",
      " 35  Normal                   2638 non-null   float64\n",
      " 36  Overall_Cond             2638 non-null   float64\n",
      " 37  Overall_Qual             2638 non-null   float64\n",
      " 38  Ratio_GarArea_Cars       2638 non-null   float64\n",
      " 39  Second_Flr_SF            2638 non-null   float64\n",
      " 40  TBath_Gr_Area_Ratio      2638 non-null   float64\n",
      " 41  TotRms_AbvGrd            2638 non-null   float64\n",
      " 42  Total_Bath               2638 non-null   float64\n",
      " 43  Total_Bsmt_Fin_SF        2638 non-null   float64\n",
      " 44  Total_Bsmt_SF            2638 non-null   float64\n",
      " 45  Year_Sold                2638 non-null   float64\n",
      " 46  neighborhoods_1          2638 non-null   float64\n",
      " 47  neighborhoods_2          2638 non-null   float64\n",
      " 48  neighborhoods_3          2638 non-null   float64\n",
      " 49  neighborhoods_4          2638 non-null   float64\n",
      " 50  neighborhoods_5          2638 non-null   float64\n",
      " 51  Sale_Price               2638 non-null   float64\n",
      "dtypes: float64(52)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 52 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Age                      2930 non-null   float64\n",
      " 1   Attchd                   2930 non-null   float64\n",
      " 2   Bedroom_AbvGr            2930 non-null   float64\n",
      " 3   Bedroom_Liv_Area_Ratio   2930 non-null   float64\n",
      " 4   Bsmt                     2930 non-null   float64\n",
      " 5   Bsmt_Cond                2930 non-null   float64\n",
      " 6   Bsmt_Exposure            2930 non-null   float64\n",
      " 7   Bsmt_Full_Bath           2930 non-null   float64\n",
      " 8   Bsmt_Half_Bath           2930 non-null   float64\n",
      " 9   Bsmt_Qual                2930 non-null   float64\n",
      " 10  Central_Air              2930 non-null   float64\n",
      " 11  Exter_Cond               2930 non-null   float64\n",
      " 12  Exter_Qual               2930 non-null   float64\n",
      " 13  External_SF              2930 non-null   float64\n",
      " 14  Fireplace_Gr_Area_Ratio  2930 non-null   float64\n",
      " 15  Fireplace_Qu             2930 non-null   float64\n",
      " 16  Fireplaces               2930 non-null   float64\n",
      " 17  First_Flr_SF             2930 non-null   float64\n",
      " 18  Full_Bath                2930 non-null   float64\n",
      " 19  Garage_Area              2930 non-null   float64\n",
      " 20  Garage_Cars              2930 non-null   float64\n",
      " 21  Garage_Cond              2930 non-null   float64\n",
      " 22  Garage_Qual              2930 non-null   float64\n",
      " 23  Gr_Area_Rms_Ratio        2930 non-null   float64\n",
      " 24  Gr_Liv_Area              2930 non-null   float64\n",
      " 25  Kitchen_AbvGr            2930 non-null   float64\n",
      " 26  Kitchen_Qual             2930 non-null   float64\n",
      " 27  Latitude                 2930 non-null   float64\n",
      " 28  Longitude                2930 non-null   float64\n",
      " 29  Lot_Area                 2930 non-null   float64\n",
      " 30  LowQ_Total_Liv_Ratio     2930 non-null   float64\n",
      " 31  Low_Qual_Fin_SF          2930 non-null   float64\n",
      " 32  Mas_Vnr_Area             2930 non-null   float64\n",
      " 33  Mo_Sold                  2930 non-null   float64\n",
      " 34  No_Garage                2930 non-null   float64\n",
      " 35  Normal                   2930 non-null   float64\n",
      " 36  Overall_Cond             2930 non-null   float64\n",
      " 37  Overall_Qual             2930 non-null   float64\n",
      " 38  Ratio_GarArea_Cars       2930 non-null   float64\n",
      " 39  Second_Flr_SF            2930 non-null   float64\n",
      " 40  TBath_Gr_Area_Ratio      2930 non-null   float64\n",
      " 41  TotRms_AbvGrd            2930 non-null   float64\n",
      " 42  Total_Bath               2930 non-null   float64\n",
      " 43  Total_Bsmt_Fin_SF        2930 non-null   float64\n",
      " 44  Total_Bsmt_SF            2930 non-null   float64\n",
      " 45  Year_Sold                2930 non-null   float64\n",
      " 46  neighborhoods_1          2930 non-null   float64\n",
      " 47  neighborhoods_2          2930 non-null   float64\n",
      " 48  neighborhoods_3          2930 non-null   float64\n",
      " 49  neighborhoods_4          2930 non-null   float64\n",
      " 50  neighborhoods_5          2930 non-null   float64\n",
      " 51  Sale_Price               2930 non-null   float64\n",
      "dtypes: float64(52)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Graph Representation \n",
    "\n",
    "As shown by the following image we can transform our dataset in a big graph. \n",
    "\n",
    "In this case, the graph is going to be a dense homogeneous graph:\n",
    "* Each node has exactly $d$ features\n",
    "* Each node has exactly $k$ edges\n",
    "* Each edge has exactly $j$ features\n",
    "* There are no isolated nodes (besides when we need to split the graph into smaller ones for train-test purposes).\n",
    "\n",
    "Naturally each house is a point in our graph, but there is **no concept of edge** (initially) as we must provided the conditions for the nodes to connect.\n",
    "\n",
    "The edges can be created using various approaches, but i preferred using the following ones:\n",
    "* By a $KNN$ edge creator, which uses latitude and longitude to compute proximity and selects the first $k$ neighbors\n",
    "* By a $Radius$ edge creator, which uses a radius $r$ to find all the closest points and then selects $k$ of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cambridge-intelligence.com/wp-content/uploads/2015/07/mapping-gif.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://cambridge-intelligence.com/wp-content/uploads/2015/07/mapping-gif.gif')\n",
    "\n",
    "# https://cambridge-intelligence.com/visualizing-your-geospatial-graph-data-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "\n",
    "def describe_dataset(dataset):\n",
    "    print(f'Dataset: {dataset}:')\n",
    "    print('======================')\n",
    "    print(f'Number of graphs: {len(dataset)}')\n",
    "    print(f'Number of features: {dataset.num_features}')\n",
    "    print(f'Number of classes: {dataset.num_classes}')\n",
    "    pass\n",
    "\n",
    "def describe_graph_obj(graph_obj):\n",
    "    print(graph_obj)\n",
    "    print('==============================================================')\n",
    "    # Gather some statistics about the graph.\n",
    "    print(f'Number of nodes: {graph_obj.num_nodes}')\n",
    "    print(f'Number of edges: {graph_obj.num_edges}')\n",
    "    print(f'Average node degree: {graph_obj.num_edges / graph_obj.num_nodes:.2f}')\n",
    "    if graph_obj.train_mask is not None:\n",
    "      print(f'Number of training nodes: {graph_obj.train_mask.sum()}')\n",
    "      print(f'Training node label rate: {int(graph_obj.train_mask.sum()) / graph_obj.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {graph_obj.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {graph_obj.has_self_loops()}')\n",
    "    print(f'Is undirected: {graph_obj.is_undirected()}')\n",
    "    pass\n",
    "\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Data Preparation\n",
    "1. Perform some transformations or cleaning operations (if not done before)\n",
    "2. Rescale Data\n",
    "3. Convert to Tensor\n",
    "4. Convert Tensor to Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling\n",
    "min_max_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling\n",
    "std_data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Split\n",
    "X = dataset.drop(labels='Sale_Price', axis=1)\n",
    "y = dataset['Sale_Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with graphs\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "1. Define the neural network that has some learnable parameters (or weights)\n",
    "2. Iterate over a dataset of inputs\n",
    "3. Process input through the network\n",
    "4. Compute the loss (how far is the output from being correct)\n",
    "5. Propagate gradients back into the networkâ€™s parameters\n",
    "6. Update the weights of the network, typically using a simple update rule\n",
    "\n",
    "Credits: [NEURAL NETWORKS - PyTorch](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate edges through k-nn\n",
    "## Use latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Graph\n",
    "import torch_geometric\n",
    "import torch_cluster\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Transform Dataset to Graph with no edges\n",
    "def dataset_to_graph(dataset, latitude_index, longitude_index):\n",
    "  # Get latitude and longitude data\n",
    "  longitude_index+=1\n",
    "  lat_long = df.iloc[:, latitude_index:longitude_index]\n",
    "  # Create a tensor for the edge creation later\n",
    "  position_tensor = torch.tensor(np.asarray(lat_long), dtype=torch.float32)\n",
    "  # Create a dataset tensor for the features\n",
    "  dataset_tensor = torch.tensor(np.asarray(df.drop(lat_long, axis=1)), dtype=torch.float32)\n",
    "  # Create Graph\n",
    "  graph = Data(x = dataset_tensor, \n",
    "               edge_index = None, \n",
    "               edge_attr = None,\n",
    "               pos = position_tensor, \n",
    "               y = None,\n",
    "               train_mask = torch.ones_like(dataset_tensor, dtype=torch.bool), \n",
    "               val_mask = torch.ones_like(dataset_tensor, dtype=torch.bool), \n",
    "               test_mask = torch.ones_like(dataset_tensor, dtype=torch.bool))\n",
    "  return graph\n",
    "\n",
    "# Cosine only for GPU\n",
    "def add_edges_knn(graph:Data, k=5, cosine=False):\n",
    "  edge_creator = T.KNNGraph(k=k, cosine=cosine, force_undirected=True)\n",
    "  return edge_creator(data=graph)\n",
    "\n",
    "\n",
    "def add_edges_radius(graph:Data, r=3, max_num_neighbors=10):\n",
    "  edge_creator = T.RadiusGraph(r=r, max_num_neighbors=max_num_neighbors)\n",
    "  return edge_creator(data=graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Model definition\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)\n",
    "\n",
    "# https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=fmXWs1dKIzD8\n",
    "# https://docs.dgl.ai/en/0.8.x/guide/training-node.html\n",
    "# https://github.com/Jiakui/awesome-gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GATConv(...)  # TODO\n",
    "        self.conv2 = GATConv(...)  # TODO\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GAT(hidden_channels=8, heads=8)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test(mask):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
    "      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
    "      return acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    val_acc = test(data.val_mask)\n",
    "    test_acc = test(data.test_mask)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ANN(nn.Module):\n",
    "  pass\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Diagnostics and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to evaluate regression models:\n",
    "1. Mean/Median of prediction\n",
    "2. Standard Deviation of prediction\n",
    "3. Range of prediction\n",
    "4. Coefficient of Determination (R2)\n",
    "5. Relative Standard Deviation/Coefficient of Variation (RSD)\n",
    "6. Relative Squared Error (RSE)\n",
    "7. Mean Absolute Error (MAE)\n",
    "8. Relative Absolute Error (RAE)\n",
    "9. Mean Squared Error (MSE)\n",
    "10. Root Mean Squared Error on Prediction (RMSE/RMSEP)\n",
    "11. Normalized Root Mean Squared Error (Norm RMSEP)\n",
    "12. Relative Root Mean Squared Error (RRMSEP)\n",
    "\n",
    "Reference:\n",
    "* [Ways to Evaluate Regression Models](https://towardsdatascience.com/ways-to-evaluate-regression-models-77a3ff45ba70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation - Predicted vs Actual\n",
    "## For each epoch display how the following scores change\n",
    "\n",
    "## R Square and Adjusted R Square\n",
    "\n",
    "## Mean Square Error(MSE) and Root Mean Square Error(RMSE)\n",
    "\n",
    "## Mean Absolute Error(MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating instances\n",
    "\n",
    "Investigate instances with the most correct predictions and with the most\n",
    "wrong predictions. Do they have some peculiarities? Any strange feature\n",
    "distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}